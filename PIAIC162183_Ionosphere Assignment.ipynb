{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Ionosphere Data Problem\n",
    "\n",
    "### Dataset Description: \n",
    "\n",
    "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
    "\n",
    "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "- All 34 are continuous\n",
    "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
    "\n",
    " <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">351</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Integer,Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">34</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">N/A</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Classification</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKFLOW :\n",
    "- Load Data\n",
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column.\n",
    "- Shuffle the data if needed.\n",
    "- Standardized the Input Variables. **Hint**: Centeralized the data\n",
    "- Split into 60 and 40 ratio.\n",
    "- Encode labels.\n",
    "- Model : 1 hidden layers including 16 unit.\n",
    "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
    "- Train the Model with Epochs (100).\n",
    "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Prediction should be > **92%**\n",
    "- Evaluation Step\n",
    "- Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data:\n",
    "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('ionosphere_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature2     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing input and splitting it into 60:40 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.     ,  0.     ,  0.50112, ...,  0.10562,  0.60674, -0.0809 ],\n",
       "       [ 1.     ,  0.     ,  1.     , ..., -1.     ,  1.     , -1.     ],\n",
       "       [ 1.     ,  0.     ,  1.     , ..., -0.20101,  0.83867, -0.20766],\n",
       "       ...,\n",
       "       [ 1.     ,  0.     ,  1.     , ..., -1.     ,  1.     , -1.     ],\n",
       "       [ 1.     ,  0.     ,  1.     , ...,  1.     ,  1.     ,  1.     ],\n",
       "       [ 1.     ,  0.     ,  1.     , ...,  0.35294,  1.     ,  0.23529]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.values[:, :-1]\n",
    "y = df.values[:, -1]\n",
    "\n",
    "x_train, x_test , y_train, y_test = train_test_split(x,y, test_size= 0.40, random_state= 7)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train[:,1:] = scaler.fit_transform(x_train[:,1:])\n",
    "x_test[:,1:]  = scaler.transform(x_test[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.68628299, ..., -0.47730486,\n",
       "         1.21644716, -0.31056737],\n",
       "       [ 1.        ,  0.        ,  0.65473611, ..., -0.2622106 ,\n",
       "         1.15769403, -0.32299092],\n",
       "       [ 1.        ,  0.        ,  0.03935743, ...,  0.05423083,\n",
       "         0.5674093 ,  0.07960857],\n",
       "       ...,\n",
       "       [ 1.        ,  0.        , -1.32154871, ...,  0.03200803,\n",
       "         1.21644716, -0.4937042 ],\n",
       "       [ 1.        ,  0.        , -1.22482534, ...,  0.13320579,\n",
       "        -0.47231315, -0.16291204],\n",
       "       [ 1.        ,  0.        , -0.83866695, ..., -1.8354539 ,\n",
       "        -0.60705146,  0.05494239]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0           1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1           1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2           1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3           1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4           1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "346         1         0   0.83508   0.08298   0.73739  -0.14706   0.84349   \n",
       "347         1         0   0.95113   0.00419   0.95183  -0.02723   0.93438   \n",
       "348         1         0   0.94701  -0.00034   0.93207  -0.03227   0.95177   \n",
       "349         1         0   0.90608  -0.01657   0.98122  -0.01989   0.95691   \n",
       "350         1         0   0.84710   0.13533   0.73638  -0.06151   0.87873   \n",
       "\n",
       "     feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0    -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1    -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2    -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3    -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4    -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "..        ...       ...        ...  ...        ...        ...        ...   \n",
       "346  -0.05567   0.90441   -0.04622  ...   -0.04202    0.83479    0.00123   \n",
       "347  -0.01920   0.94590    0.01606  ...    0.01361    0.93522    0.04925   \n",
       "348  -0.03431   0.95584    0.02446  ...    0.03193    0.92489    0.02542   \n",
       "349  -0.03646   0.85746    0.00110  ...   -0.02099    0.89147   -0.07760   \n",
       "350   0.08260   0.88928   -0.09139  ...   -0.15114    0.81147   -0.04822   \n",
       "\n",
       "     feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0      0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      1  \n",
       "1     -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      0  \n",
       "2      0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      1  \n",
       "3      1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      0  \n",
       "4      0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      1  \n",
       "..         ...        ...        ...        ...        ...        ...    ...  \n",
       "346    1.00000    0.12815    0.86660   -0.10714    0.90546   -0.04307      1  \n",
       "347    0.93159    0.08168    0.94066   -0.00035    0.91483    0.04712      1  \n",
       "348    0.92120    0.02242    0.92459    0.00442    0.92697   -0.00577      1  \n",
       "349    0.82983   -0.17238    0.96022   -0.03757    0.87403   -0.16243      1  \n",
       "350    0.78207   -0.00703    0.75747   -0.06678    0.85764   -0.06151      1  \n",
       "\n",
       "[351 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'column_ai': 'label'}, inplace=True)\n",
    "df['label'] = df.label.astype('category')\n",
    "encoding = {'g': 1, 'b': 0}\n",
    "df.label.replace(encoding, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16,activation = 'relu',input_dim = 34))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer = 'rmsprop',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/110\n",
      "210/210 [==============================] - 0s 662us/step - loss: 1.1156 - accuracy: 0.2524\n",
      "Epoch 2/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 1.0646 - accuracy: 0.2619\n",
      "Epoch 3/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 1.0299 - accuracy: 0.2667\n",
      "Epoch 4/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 1.0020 - accuracy: 0.2667\n",
      "Epoch 5/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.9782 - accuracy: 0.2714\n",
      "Epoch 6/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.9571 - accuracy: 0.2714\n",
      "Epoch 7/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.9381 - accuracy: 0.2905\n",
      "Epoch 8/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.9207 - accuracy: 0.3000\n",
      "Epoch 9/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.9043 - accuracy: 0.3143\n",
      "Epoch 10/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.8888 - accuracy: 0.3238\n",
      "Epoch 11/110\n",
      "210/210 [==============================] - 0s 24us/step - loss: 0.8740 - accuracy: 0.3286\n",
      "Epoch 12/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.8600 - accuracy: 0.3429\n",
      "Epoch 13/110\n",
      "210/210 [==============================] - 0s 24us/step - loss: 0.8467 - accuracy: 0.3476\n",
      "Epoch 14/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.8339 - accuracy: 0.3476\n",
      "Epoch 15/110\n",
      "210/210 [==============================] - 0s 24us/step - loss: 0.8215 - accuracy: 0.3571\n",
      "Epoch 16/110\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.8096 - accuracy: 0.3667\n",
      "Epoch 17/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.7980 - accuracy: 0.3762\n",
      "Epoch 18/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.7865 - accuracy: 0.3952\n",
      "Epoch 19/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.7753 - accuracy: 0.4095\n",
      "Epoch 20/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.7646 - accuracy: 0.4190\n",
      "Epoch 21/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.7542 - accuracy: 0.4429\n",
      "Epoch 22/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.7440 - accuracy: 0.4714\n",
      "Epoch 23/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.7340 - accuracy: 0.5143\n",
      "Epoch 24/110\n",
      "210/210 [==============================] - 0s 24us/step - loss: 0.7242 - accuracy: 0.5476\n",
      "Epoch 25/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.7147 - accuracy: 0.5667\n",
      "Epoch 26/110\n",
      "210/210 [==============================] - 0s 24us/step - loss: 0.7054 - accuracy: 0.5857\n",
      "Epoch 27/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.6962 - accuracy: 0.5857\n",
      "Epoch 28/110\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.6872 - accuracy: 0.6095\n",
      "Epoch 29/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.6785 - accuracy: 0.6190\n",
      "Epoch 30/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.6701 - accuracy: 0.6286\n",
      "Epoch 31/110\n",
      "210/210 [==============================] - 0s 24us/step - loss: 0.6618 - accuracy: 0.6333\n",
      "Epoch 32/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.6538 - accuracy: 0.6381\n",
      "Epoch 33/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.6460 - accuracy: 0.6524\n",
      "Epoch 34/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.6383 - accuracy: 0.6667\n",
      "Epoch 35/110\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.6309 - accuracy: 0.6857\n",
      "Epoch 36/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.6235 - accuracy: 0.6857\n",
      "Epoch 37/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.6163 - accuracy: 0.7000\n",
      "Epoch 38/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.6092 - accuracy: 0.7048\n",
      "Epoch 39/110\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.6022 - accuracy: 0.7048\n",
      "Epoch 40/110\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.5954 - accuracy: 0.7190\n",
      "Epoch 41/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.5888 - accuracy: 0.7429\n",
      "Epoch 42/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.5824 - accuracy: 0.7524\n",
      "Epoch 43/110\n",
      "210/210 [==============================] - 0s 43us/step - loss: 0.5762 - accuracy: 0.7619\n",
      "Epoch 44/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.5701 - accuracy: 0.7667\n",
      "Epoch 45/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.5641 - accuracy: 0.7714\n",
      "Epoch 46/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.5582 - accuracy: 0.7810\n",
      "Epoch 47/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.5524 - accuracy: 0.7810\n",
      "Epoch 48/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.5468 - accuracy: 0.7952\n",
      "Epoch 49/110\n",
      "210/210 [==============================] - 0s 24us/step - loss: 0.5413 - accuracy: 0.8000\n",
      "Epoch 50/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.5359 - accuracy: 0.8000\n",
      "Epoch 51/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.5306 - accuracy: 0.8000\n",
      "Epoch 52/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.5255 - accuracy: 0.8048\n",
      "Epoch 53/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.5203 - accuracy: 0.8000\n",
      "Epoch 54/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.5153 - accuracy: 0.8000\n",
      "Epoch 55/110\n",
      "210/210 [==============================] - 0s 24us/step - loss: 0.5103 - accuracy: 0.8048\n",
      "Epoch 56/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.5054 - accuracy: 0.8048\n",
      "Epoch 57/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.5006 - accuracy: 0.8143\n",
      "Epoch 58/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4959 - accuracy: 0.8333\n",
      "Epoch 59/110\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.4912 - accuracy: 0.8429\n",
      "Epoch 60/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4866 - accuracy: 0.8429\n",
      "Epoch 61/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.4821 - accuracy: 0.8571\n",
      "Epoch 62/110\n",
      "210/210 [==============================] - 0s 24us/step - loss: 0.4777 - accuracy: 0.8524\n",
      "Epoch 63/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4733 - accuracy: 0.8571\n",
      "Epoch 64/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4691 - accuracy: 0.8524\n",
      "Epoch 65/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4649 - accuracy: 0.8524\n",
      "Epoch 66/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4608 - accuracy: 0.8571\n",
      "Epoch 67/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4567 - accuracy: 0.8524\n",
      "Epoch 68/110\n",
      "210/210 [==============================] - 0s 24us/step - loss: 0.4527 - accuracy: 0.8524\n",
      "Epoch 69/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4487 - accuracy: 0.8524\n",
      "Epoch 70/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4448 - accuracy: 0.8524\n",
      "Epoch 71/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.4409 - accuracy: 0.8571\n",
      "Epoch 72/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4370 - accuracy: 0.8571\n",
      "Epoch 73/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.4331 - accuracy: 0.8571\n",
      "Epoch 74/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4293 - accuracy: 0.8571\n",
      "Epoch 75/110\n",
      "210/210 [==============================] - 0s 24us/step - loss: 0.4255 - accuracy: 0.8571\n",
      "Epoch 76/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4218 - accuracy: 0.8571\n",
      "Epoch 77/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4181 - accuracy: 0.8619\n",
      "Epoch 78/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4145 - accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/110\n",
      "210/210 [==============================] - 0s 24us/step - loss: 0.4110 - accuracy: 0.8667\n",
      "Epoch 80/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4075 - accuracy: 0.8667\n",
      "Epoch 81/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4040 - accuracy: 0.8667\n",
      "Epoch 82/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.4006 - accuracy: 0.8667\n",
      "Epoch 83/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.3973 - accuracy: 0.8667\n",
      "Epoch 84/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.3939 - accuracy: 0.8667\n",
      "Epoch 85/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.3906 - accuracy: 0.8667\n",
      "Epoch 86/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.3873 - accuracy: 0.8667\n",
      "Epoch 87/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.3841 - accuracy: 0.8667\n",
      "Epoch 88/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.3809 - accuracy: 0.8667\n",
      "Epoch 89/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.3778 - accuracy: 0.8667\n",
      "Epoch 90/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.3747 - accuracy: 0.8667\n",
      "Epoch 91/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.3717 - accuracy: 0.8667\n",
      "Epoch 92/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.3688 - accuracy: 0.8667\n",
      "Epoch 93/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.3658 - accuracy: 0.8714\n",
      "Epoch 94/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.3629 - accuracy: 0.8714\n",
      "Epoch 95/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.3600 - accuracy: 0.8714\n",
      "Epoch 96/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.3571 - accuracy: 0.8714\n",
      "Epoch 97/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.3543 - accuracy: 0.8714\n",
      "Epoch 98/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.3514 - accuracy: 0.8714\n",
      "Epoch 99/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.3487 - accuracy: 0.8714\n",
      "Epoch 100/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.3460 - accuracy: 0.8714\n",
      "Epoch 101/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.3433 - accuracy: 0.8714\n",
      "Epoch 102/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.3407 - accuracy: 0.8714\n",
      "Epoch 103/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.3380 - accuracy: 0.8714\n",
      "Epoch 104/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.3354 - accuracy: 0.8762\n",
      "Epoch 105/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.3328 - accuracy: 0.8762\n",
      "Epoch 106/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.3303 - accuracy: 0.8762\n",
      "Epoch 107/110\n",
      "210/210 [==============================] - 0s 14us/step - loss: 0.3278 - accuracy: 0.8762\n",
      "Epoch 108/110\n",
      "210/210 [==============================] - 0s 19us/step - loss: 0.3253 - accuracy: 0.8762\n",
      "Epoch 109/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.3229 - accuracy: 0.8762\n",
      "Epoch 110/110\n",
      "210/210 [==============================] - 0s 10us/step - loss: 0.3205 - accuracy: 0.8762\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train,y_train , epochs = 110, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                560       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 577\n",
      "Trainable params: 577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 111us/step\n",
      "accuracy: 92.20%\n"
     ]
    }
   ],
   "source": [
    "scores =model.evaluate(x_test, y_test)\n",
    "scores\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8943895 ],\n",
       "       [0.8637259 ],\n",
       "       [0.76778436],\n",
       "       [0.8597241 ],\n",
       "       [0.8094673 ],\n",
       "       [0.79324067],\n",
       "       [0.5118331 ],\n",
       "       [0.9250439 ],\n",
       "       [0.84335184],\n",
       "       [0.824691  ],\n",
       "       [0.85157055],\n",
       "       [0.35280895],\n",
       "       [0.1287702 ],\n",
       "       [0.86152065],\n",
       "       [0.793431  ],\n",
       "       [0.02140692],\n",
       "       [0.01170462],\n",
       "       [0.39107525],\n",
       "       [0.06379595],\n",
       "       [0.8191296 ],\n",
       "       [0.8247581 ],\n",
       "       [0.30320168],\n",
       "       [0.3505027 ],\n",
       "       [0.26204413],\n",
       "       [0.70816344],\n",
       "       [0.87647384],\n",
       "       [0.18371409],\n",
       "       [0.43457115],\n",
       "       [0.8647858 ],\n",
       "       [0.8029099 ],\n",
       "       [0.6796166 ],\n",
       "       [0.70034885],\n",
       "       [0.2503944 ],\n",
       "       [0.87285566],\n",
       "       [0.66906893],\n",
       "       [0.6866173 ],\n",
       "       [0.9373125 ],\n",
       "       [0.426012  ],\n",
       "       [0.95821893],\n",
       "       [0.15630966],\n",
       "       [0.03995118],\n",
       "       [0.67027354],\n",
       "       [0.8624816 ],\n",
       "       [0.23054197],\n",
       "       [0.05906048],\n",
       "       [0.808625  ],\n",
       "       [0.91618854],\n",
       "       [0.15924025],\n",
       "       [0.3793384 ],\n",
       "       [0.10309708],\n",
       "       [0.87915385],\n",
       "       [0.53947014],\n",
       "       [0.4151742 ],\n",
       "       [0.6712186 ],\n",
       "       [0.85749316],\n",
       "       [0.66053134],\n",
       "       [0.55335575],\n",
       "       [0.05316964],\n",
       "       [0.69634444],\n",
       "       [0.5774913 ],\n",
       "       [0.7971808 ],\n",
       "       [0.79354674],\n",
       "       [0.57025105],\n",
       "       [0.15872663],\n",
       "       [0.74687994],\n",
       "       [0.7319101 ],\n",
       "       [0.6502168 ],\n",
       "       [0.9644886 ],\n",
       "       [0.673945  ],\n",
       "       [0.5733821 ],\n",
       "       [0.5791151 ],\n",
       "       [0.59707344],\n",
       "       [0.86614436],\n",
       "       [0.8655214 ],\n",
       "       [0.82389736],\n",
       "       [0.7951009 ],\n",
       "       [0.26165766],\n",
       "       [0.73378795],\n",
       "       [0.7342102 ],\n",
       "       [0.76866376],\n",
       "       [0.8545537 ],\n",
       "       [0.7892493 ],\n",
       "       [0.52888167],\n",
       "       [0.07320616],\n",
       "       [0.35847092],\n",
       "       [0.6990936 ],\n",
       "       [0.68100417],\n",
       "       [0.7839211 ],\n",
       "       [0.72779095],\n",
       "       [0.6070317 ],\n",
       "       [0.69406646],\n",
       "       [0.866495  ],\n",
       "       [0.83836806],\n",
       "       [0.11035404],\n",
       "       [0.7581171 ],\n",
       "       [0.74941516],\n",
       "       [0.14446521],\n",
       "       [0.91562116],\n",
       "       [0.15539667],\n",
       "       [0.7302151 ],\n",
       "       [0.78987277],\n",
       "       [0.4808921 ],\n",
       "       [0.44143355],\n",
       "       [0.19285545],\n",
       "       [0.95799017],\n",
       "       [0.2505324 ],\n",
       "       [0.9071281 ],\n",
       "       [0.68917453],\n",
       "       [0.5714514 ],\n",
       "       [0.8503318 ],\n",
       "       [0.16897178],\n",
       "       [0.39832932],\n",
       "       [0.19411305],\n",
       "       [0.63054824],\n",
       "       [0.48343828],\n",
       "       [0.19628668],\n",
       "       [0.9269487 ],\n",
       "       [0.8729044 ],\n",
       "       [0.14446521],\n",
       "       [0.6120007 ],\n",
       "       [0.19987431],\n",
       "       [0.72115266],\n",
       "       [0.5880592 ],\n",
       "       [0.8232615 ],\n",
       "       [0.4942667 ],\n",
       "       [0.6490383 ],\n",
       "       [0.7825738 ],\n",
       "       [0.78930366],\n",
       "       [0.7847892 ],\n",
       "       [0.7435976 ],\n",
       "       [0.83768964],\n",
       "       [0.41511503],\n",
       "       [0.43940368],\n",
       "       [0.745583  ],\n",
       "       [0.4497553 ],\n",
       "       [0.6946194 ],\n",
       "       [0.68497354],\n",
       "       [0.16774952],\n",
       "       [0.24809864],\n",
       "       [0.19789433],\n",
       "       [0.04913701]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
